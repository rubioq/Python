{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b92b6ef",
   "metadata": {},
   "source": [
    "# Examen Enero 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6da39",
   "metadata": {},
   "source": [
    "### Bioinformática y Análisis Genómico\n",
    "### Grado en Bioquímica\n",
    "### Universidad de Sevilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341013f8",
   "metadata": {},
   "source": [
    "[Keras](https://keras.io/) es una librería de Python que permite crear de forma sencilla redes neuronales y se encuentra dentro de la plataforma [TensorFlow](https://www.tensorflow.org/). Para instalarlo, basta utilizar la siguiente línea de código (descomentándola):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c5cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.1.4 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-15.0.6.1 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3e4da",
   "metadata": {},
   "source": [
    "Además, en este examen se utilizarán los paquetes `numpy`, `pandas` y `sklearn`, que se deberás tener instalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb752367",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4271098162.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [4]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install numpy\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# pip install numpy\n",
    "# pip install pandas\n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcc243",
   "metadata": {},
   "source": [
    "Además, como se van a emplear números pseudoaletorios durante el ejercicio, hay que definir una semilla para que el análisis sea reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210caad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import random as tensorflow_random\n",
    "\n",
    "tensorflow_random.set_seed(394867)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86ae56",
   "metadata": {},
   "source": [
    "Después hay que importar los paquetes que van a permitir la división del conjunto de datos en entrenamiento y test y definir la semilla para numpy (paquete para trabajar con arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f238e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "\n",
    "numpy.random.seed(43958734)\n",
    "numpy.set_printoptions(threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102994d",
   "metadata": {},
   "source": [
    "Finalmente importamos el paquete `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9739575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0782cbc",
   "metadata": {},
   "source": [
    "## Ejercicio de redes naturales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7d50d",
   "metadata": {},
   "source": [
    "Se proporciona un fichero de datos ómicos con el nombre `keras_cancer.tsv`. Este fichero recoge información de expresión génica y miRNAs de 220 pacientes de cáncer de mama y la clasificación de cada uno según el tipo de cáncer que presenta. De esta forma, las primeras 200 columnas contienen datos de mRNAs (nombradas como los genes a los que corresponde el transcrito), las 184 siguientes de miRNAs (nombradas como los miRNAs cuantificados, con el identificador hsa-número) y la última columna, type, contiene información del tipo de cáncer, donde un valor de 1 se asocia a Basal, uno de 2 a Her2 y uno de 3 a LumA. Usa read_csv de pandas para leer los datos, almacénalos en una variable llamada breast y pre-visualízalos con head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b88523d9",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTN2</th>\n",
       "      <th>NDRG2</th>\n",
       "      <th>CCDC113</th>\n",
       "      <th>FAM63A</th>\n",
       "      <th>ACADS</th>\n",
       "      <th>GMDS</th>\n",
       "      <th>HLA-H</th>\n",
       "      <th>SEMA4A</th>\n",
       "      <th>ETS2</th>\n",
       "      <th>LIMD2</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-9-2</th>\n",
       "      <th>hsa-mir-92a-1</th>\n",
       "      <th>hsa-mir-92a-2</th>\n",
       "      <th>hsa-mir-92b</th>\n",
       "      <th>hsa-mir-93</th>\n",
       "      <th>hsa-mir-96</th>\n",
       "      <th>hsa-mir-98</th>\n",
       "      <th>hsa-mir-99a</th>\n",
       "      <th>hsa-mir-99b</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.362183</td>\n",
       "      <td>7.533461</td>\n",
       "      <td>3.956124</td>\n",
       "      <td>4.457170</td>\n",
       "      <td>2.256817</td>\n",
       "      <td>6.017940</td>\n",
       "      <td>5.006907</td>\n",
       "      <td>3.217812</td>\n",
       "      <td>4.734446</td>\n",
       "      <td>5.099598</td>\n",
       "      <td>...</td>\n",
       "      <td>12.779765</td>\n",
       "      <td>11.320936</td>\n",
       "      <td>15.288781</td>\n",
       "      <td>5.832308</td>\n",
       "      <td>13.272791</td>\n",
       "      <td>6.920198</td>\n",
       "      <td>6.651011</td>\n",
       "      <td>8.745468</td>\n",
       "      <td>15.783732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.984492</td>\n",
       "      <td>7.455194</td>\n",
       "      <td>5.427623</td>\n",
       "      <td>5.440957</td>\n",
       "      <td>4.028813</td>\n",
       "      <td>4.341692</td>\n",
       "      <td>6.178668</td>\n",
       "      <td>2.864659</td>\n",
       "      <td>5.411029</td>\n",
       "      <td>4.211397</td>\n",
       "      <td>...</td>\n",
       "      <td>13.823930</td>\n",
       "      <td>12.098454</td>\n",
       "      <td>14.262681</td>\n",
       "      <td>6.900878</td>\n",
       "      <td>14.086331</td>\n",
       "      <td>6.292604</td>\n",
       "      <td>6.329947</td>\n",
       "      <td>9.235832</td>\n",
       "      <td>14.902776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.727323</td>\n",
       "      <td>8.079968</td>\n",
       "      <td>2.227300</td>\n",
       "      <td>5.543480</td>\n",
       "      <td>2.629855</td>\n",
       "      <td>6.363030</td>\n",
       "      <td>6.039563</td>\n",
       "      <td>5.946028</td>\n",
       "      <td>5.651670</td>\n",
       "      <td>3.304513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.544669</td>\n",
       "      <td>9.040364</td>\n",
       "      <td>13.924606</td>\n",
       "      <td>4.563778</td>\n",
       "      <td>13.511479</td>\n",
       "      <td>5.330801</td>\n",
       "      <td>5.910797</td>\n",
       "      <td>9.333587</td>\n",
       "      <td>13.661209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.363996</td>\n",
       "      <td>5.793750</td>\n",
       "      <td>3.544866</td>\n",
       "      <td>4.737114</td>\n",
       "      <td>4.269101</td>\n",
       "      <td>4.001104</td>\n",
       "      <td>7.087633</td>\n",
       "      <td>5.007565</td>\n",
       "      <td>5.902449</td>\n",
       "      <td>5.479451</td>\n",
       "      <td>...</td>\n",
       "      <td>11.540357</td>\n",
       "      <td>10.337624</td>\n",
       "      <td>14.004158</td>\n",
       "      <td>6.174951</td>\n",
       "      <td>12.868614</td>\n",
       "      <td>4.931573</td>\n",
       "      <td>5.409937</td>\n",
       "      <td>9.813171</td>\n",
       "      <td>14.805293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.447562</td>\n",
       "      <td>7.158993</td>\n",
       "      <td>4.691256</td>\n",
       "      <td>4.808728</td>\n",
       "      <td>2.442135</td>\n",
       "      <td>7.029723</td>\n",
       "      <td>5.936138</td>\n",
       "      <td>5.901459</td>\n",
       "      <td>6.641225</td>\n",
       "      <td>5.508654</td>\n",
       "      <td>...</td>\n",
       "      <td>10.795053</td>\n",
       "      <td>12.018595</td>\n",
       "      <td>15.720121</td>\n",
       "      <td>8.151821</td>\n",
       "      <td>13.942631</td>\n",
       "      <td>4.109904</td>\n",
       "      <td>6.511839</td>\n",
       "      <td>8.355920</td>\n",
       "      <td>15.116468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RTN2     NDRG2   CCDC113    FAM63A     ACADS      GMDS     HLA-H  \\\n",
       "0  4.362183  7.533461  3.956124  4.457170  2.256817  6.017940  5.006907   \n",
       "1  1.984492  7.455194  5.427623  5.440957  4.028813  4.341692  6.178668   \n",
       "2  1.727323  8.079968  2.227300  5.543480  2.629855  6.363030  6.039563   \n",
       "3  4.363996  5.793750  3.544866  4.737114  4.269101  4.001104  7.087633   \n",
       "4  2.447562  7.158993  4.691256  4.808728  2.442135  7.029723  5.936138   \n",
       "\n",
       "     SEMA4A      ETS2     LIMD2  ...  hsa-mir-9-2  hsa-mir-92a-1  \\\n",
       "0  3.217812  4.734446  5.099598  ...    12.779765      11.320936   \n",
       "1  2.864659  5.411029  4.211397  ...    13.823930      12.098454   \n",
       "2  5.946028  5.651670  3.304513  ...     6.544669       9.040364   \n",
       "3  5.007565  5.902449  5.479451  ...    11.540357      10.337624   \n",
       "4  5.901459  6.641225  5.508654  ...    10.795053      12.018595   \n",
       "\n",
       "   hsa-mir-92a-2  hsa-mir-92b  hsa-mir-93  hsa-mir-96  hsa-mir-98  \\\n",
       "0      15.288781     5.832308   13.272791    6.920198    6.651011   \n",
       "1      14.262681     6.900878   14.086331    6.292604    6.329947   \n",
       "2      13.924606     4.563778   13.511479    5.330801    5.910797   \n",
       "3      14.004158     6.174951   12.868614    4.931573    5.409937   \n",
       "4      15.720121     8.151821   13.942631    4.109904    6.511839   \n",
       "\n",
       "   hsa-mir-99a  hsa-mir-99b  type  \n",
       "0     8.745468    15.783732     1  \n",
       "1     9.235832    14.902776     1  \n",
       "2     9.333587    13.661209     1  \n",
       "3     9.813171    14.805293     1  \n",
       "4     8.355920    15.116468     1  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast = pandas.read_csv(\"keras_cancer.tsv\", sep=\"\\t\")\n",
    "breast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaea4de",
   "metadata": {},
   "source": [
    "Confirma que las dimensiones son correctas usando shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f754877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 385)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eccd5",
   "metadata": {},
   "source": [
    "Separamos en atributos de predicción y objetivo, en este caso vamos el objetivo es predecir el tipo de cáncer a partir de los datos de expresión génica. Para esto define atributos como las primeras 200 columnas de la tabla de datos usando iloc, estas serán las variables predictoras. También define objetivo como la columna identificada con type en los datos guardados en breast. Esta será la variable respuesta que se quiere predecir. Es necesario transformar estos datos a un array de Numpy, compatible con Keras, usando to_numpy(). Muestras estas variables con print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39d2e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.36218331 7.53346145 3.95612417 ... 3.99198186 3.35263746 7.88092301]\n",
      " [1.98449231 7.45519376 5.42762306 ... 3.34369865 3.63714211 7.80708187]\n",
      " [1.72732287 8.07996824 2.22730024 ... 3.28931416 3.63387947 7.44171248]\n",
      " ...\n",
      " [4.44270845 7.03873191 3.86784085 ... 5.4663389  4.40897879 7.79461371]\n",
      " [4.58795195 4.80163296 4.43026828 ... 5.58968014 4.53612901 8.11940302]\n",
      " [3.48796381 5.43834437 4.20031809 ... 5.26583021 2.95082991 7.41317155]]\n",
      "[1 1 1 ... 3 3 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(220, 200)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributos = breast.iloc[:,0:200].to_numpy()\n",
    "objetivo = breast.iloc[:,384].to_numpy()\n",
    "print(atributos)\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c79cb6",
   "metadata": {},
   "source": [
    "A continuación, es necesario definir los subconjuntos de entrenamiento y prueba (tanto para  los atributos como objetivo) para la construcción y evaluación de redes neuronales mediante aprendizaje supervisado. Aquí definiremos como conjunto de entrenamiento a un 80% de las instancias o pacientes mientras que el 20% restante se usará como conjunto de test sobre el que posteriormente se probará el modelo para evaluar su eficacia. Realiza este paso usando model_selection.train_test_split con los argumentos oportunos. Usa los siguientes nombres de variables atributos_entrenamiento, atributos_prueba, objetivo_entrenamiento y objetivo_prueba. Muestra con print las dimensiones (shape) de cada variable definida en este paso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9152db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?model_selection.train_test_split\n",
    "atributos_entrenamiento, atributos_prueba, objetivo_entrenamiento, objetivo_prueba = model_selection.train_test_split(atributos, objetivo, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7a56907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 200)\n",
      "(44, 200)\n",
      "(176,)\n",
      "(44,)\n"
     ]
    }
   ],
   "source": [
    "print(atributos_entrenamiento.shape)\n",
    "print(atributos_prueba.shape)\n",
    "print(objetivo_entrenamiento.shape)\n",
    "print(objetivo_prueba.shape)\n",
    "# print(objetivo_entrenamiento)\n",
    "# print(objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb7d87",
   "metadata": {},
   "source": [
    "Para evitar problemas de desbordamiento numérico y realizar un preprocesamiento de los datos para evitar valores atípicos, se puede emplear una capa de normalización, usando la instancia de la clase keras `layers.experimental.preprocessing.Normalization`. En este caso, se pide que se guarde en una variable llamada normalizador y que se use sobre ella el método `adapt` para aplicarlo sobre los atributos de entrenamiento guardados anteriormente en la variable atributos_entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22a573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.experimental.preprocessing.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5230f",
   "metadata": {},
   "source": [
    "A partir de estos datos, ya se puede emplear Keras para construir la red y entrenar el modelo.  Para esto, se va a emplear un enfoque secuencial en el que se va a construir la red definiendo una por una las distintas capas. De esta forma, se comienza definiendo la primera capa (tipo de capa, número de neuronas, etc) y se van añadiendo una a una las distintas capas hasta llegar a la de salida. Almacena esta red en la variable net_breast e inicializala usando Sequential de keras. Añade las capas sucesivamente con add.\n",
    "\n",
    "La primera capa o capa de entrada se construye con la clase `Input`, y hay que definir la forma de los datos de entrada como un array con el número de dimensiones necesario. En este caso, una dimensión de 200 atributos.\n",
    "\n",
    "Justo después de la capa de entrada se debe añadir la capa de normalización previamente configurada que, al haber ya sido adaptada a los datos de entrada, no necesita una especificación del número de neuronas que debe contener. Esta capa se almecenó en normalizador.\n",
    "\n",
    "Como vamos a trabajar con una red neuronal con neuronas completamente conectadas, el resto de las capas se contruyen con la clase `layers.Dense`, donde de nuevo hay que especificar la cantidad de neuronas y, en este caso, la función de activación, es decir, la función que se aplica en la salida de cada neurona tras la integración de las señales que llegan a ella. Para este problema, conviene restringirse al uso de las funciones de activación `softmax` y `sigmoid`. De esta forma añade una capa oculta con 15 neuronas y función de activación softmax. Por último, añade la capa de salida con 3 neuronas y de nuevo softmax como función de activación. \n",
    "\n",
    "Hay que tener en cuenta que la capa de salida debe contener un número de neuronas igual al número de clases de salida que queremos predecir (para este caso concreto, dependiendo de las funciones que se usen para definir y compilar la red esto puede variar) y que se le puede aplicar también una función de activación o dejar la función identidad que se usa por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8cd8876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_breast, Sequential de keras, add para añadir las capas\n",
    "net_breast = keras.Sequential()\n",
    "net_breast.add(keras.Input(shape=(200,)))\n",
    "net_breast.add(normalizador)\n",
    "net_breast.add(keras.layers.Dense(15, activation=\"softmax\"))\n",
    "net_breast.add(keras.layers.Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260daea8",
   "metadata": {},
   "source": [
    "El método `summary` se usa para obtener un resumen de la estructura de la red. Para cada una de las capas, indica la forma de su salida y su número de parámetros La forma de la salida se representa como un array donde el primer número muestra el número de lotes (`None` implica que se especificará más adelante) y los siguientes, el número de salidas en cada dimensión del array. En el caso de la capa de entrada, no aparece ya que no posee parámetros. En la parte inferior se muestra el número de parámetros totales y cuántos de ellos son o no entrenables. Los parámetros entrenables son los que la red aprende y modifica mediante el algoritmo de entrenamiento, que serían el peso de la conexión de cada neurona de la capa anterior con las neuronas de la capa actual más el sesgo de cada una de las neuronas de la capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f83f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 200)              401       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 15)                3015      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,464\n",
      "Trainable params: 3,063\n",
      "Non-trainable params: 401\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net_breast.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44025a4",
   "metadata": {},
   "source": [
    "Para entrenar una red neuronal hay que compilarla usando compile. Para esto, se define el algoritmo de aprendizaje u optimizador (con el atributo *optimizer* seguido del nombre) y la función de pérdida (*loss*) a minimizar y, de forma opcional, las métricas que queremos que se muestren en el entrenamiento además del valor de la función de pérdida (*metrics*). En este caso, se recomienda usar como optimizador el descenso estocástico por el gradiente (clase `optimizers.SGD`) y modular su parámetro *learning_rate* hasta obtener el rendimiento deseado (por defecto toma un valor de 0.01, se sugiere usar el valor 0.07). Este parámetro define la velocidad a la que una red puede modificar sus parámetros entrenables a lo largo de los distintos pasos de entrenamiento, de manera que mayores valores producen un cambio mayor. Se recomienda usar como función de pérdida (*loss*) *categorical_crossentropy* y como métrica (*metrics*) *accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c6bfa532",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_breast.compile(optimizer=keras.optimizers.SGD(learning_rate=0.07), loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
    "# !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509007f",
   "metadata": {},
   "source": [
    "Una vez compilada la red con la información anterior, sólo falta entrenarla usando el método `fit` sobre nuestro conjunto de entrenamiento, definiendo los atributos por un lado y el objetivo o salida por otro.\n",
    "\n",
    "El optimizador es el que se conoce como algoritmo de retropropagación de la red, se usa para actualizar los pesos y los sesgos. En lugar de realizar esta actualización con todos los ejemplos de entrenamiento, se pueden crear subconjuntos aleatorios de ellos y se irán actualizando tras procesar cada uno de esos subconjuntos o lotes (*batch*), de manera que cuando se hayan considerado todos los lotes, habrá transcurrido un paso completo del algoritmo, una época (*epoch*). A la hora de entrenar la red, estos parámetros tienen mucho peso, ya que definen el número de pasos de entrenamiento que estamos permitiendo para nuestra red. El tamaño de cada lote se especifica en el argumento *batch_size* y el número de épocas, en *epochs*. Recuerda que los atributos y objetivos se encuentran almacenados en atributos_entrenamiento y objetivo_entrenamiento. Se sugiera usar batch_size=5 y epochs=20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d38e5b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 4ms/step - loss: 1.0129 - accuracy: 0.5057\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8146 - accuracy: 0.7045\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.8807\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.9261\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.9432\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.9716\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.9886\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.9943\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9943\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9943\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9943\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1292 - accuracy: 0.9943\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.9943\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1076 - accuracy: 0.9943\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9943\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9943\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9943\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9943\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9943\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2182c2eee50>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_breast.fit(atributos_entrenamiento,(objetivo_entrenamiento-1),batch_size=5,epochs=20)\n",
    "# !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeca057",
   "metadata": {},
   "source": [
    "Una vez entrenada la red, podemos observar los valores de las métricas de precisión sobre el propio conjunto de entrenamiento (prediciendo los mismos ejemplos con los que se está entrenando). Sin embargo, puede ser que haya memorizado esos datos pero no pueda generalizar para otros nuevos, es lo que se denomina sobreajuste y se puede determinar utilizando el método `evaluate` para aplicar la red entrenada sobre el conjunto de prueba, de forma que valores de las métricas similares a las obtenidas sobre el entrenamiento indican que no existe este sobreajuste. Recuerda que el conjunto de evaluación se almacenó en atributos_prueba y objetivo_prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "98f2b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08539498597383499, 0.9772727489471436]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_breast.evaluate(atributos_prueba,(objetivo_prueba-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f998d1",
   "metadata": {},
   "source": [
    "Para predecir los valores de nuevas instancias, simplemente le pasamos a la red los valores de sus atributos y nos devolverá tres valores para cada uno, que serían los valores de probabilidad devueltos por cada una de las neuronas de salida, por lo que el mayor de los tres será la clase predicha por la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd9fdb",
   "metadata": {},
   "source": [
    "Con `argmax` obtenemos la clase de mayor probabilidad para cada instancia usando el argumento axis=1 para indicarle que mire en cada subarray. Así obtenemos que para las primeras 5 instancias del conjunto, la clase predicha es la primera (recordar que en Python los índices empiezan por el 0), que se correspondería con Basal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9f9b2f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.argmax(net_breast(atributos), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
